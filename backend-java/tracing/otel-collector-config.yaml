# ============================================================================
# Smartup LMS - OpenTelemetry Collector Configuration
# Receives, processes, and exports telemetry data
# ============================================================================

receivers:
  # OTLP receiver for traces, metrics, and logs
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # Zipkin receiver for legacy applications
  zipkin:
    endpoint: 0.0.0.0:9411

  # Jaeger receiver
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832

  # Prometheus receiver for metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 10s
          static_configs:
            - targets: ['0.0.0.0:8888']

processors:
  # Batch processor for better performance
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048

  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 1000
    spike_limit_mib: 200

  # Resource processor to add common attributes
  resource:
    attributes:
      - key: environment
        value: production
        action: upsert
      - key: service.namespace
        value: freelms
        action: upsert

  # Attributes processor for span enrichment
  attributes:
    actions:
      - key: http.client_ip
        action: hash
      - key: user.id
        action: hash

  # Tail sampling for intelligent trace sampling
  tail_sampling:
    decision_wait: 10s
    num_traces: 100000
    expected_new_traces_per_sec: 1000
    policies:
      # Always sample errors
      - name: errors-policy
        type: status_code
        status_code:
          status_codes: [ERROR]
      # Sample slow requests
      - name: latency-policy
        type: latency
        latency:
          threshold_ms: 500
      # Sample a percentage of other traces
      - name: probabilistic-policy
        type: probabilistic
        probabilistic:
          sampling_percentage: 10

exporters:
  # Jaeger exporter
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true

  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: freelms
    const_labels:
      environment: production

  # Logging exporter for debugging
  logging:
    verbosity: normal
    sampling_initial: 5
    sampling_thereafter: 200

  # OTLP exporter (for forwarding to other backends)
  otlp:
    endpoint: jaeger:4317
    tls:
      insecure: true

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133

  # Performance profiler
  pprof:
    endpoint: 0.0.0.0:1888

  # zPages for debugging
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]

  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp, zipkin, jaeger]
      processors: [memory_limiter, resource, attributes, tail_sampling, batch]
      exporters: [jaeger, logging]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus]
      processors: [memory_limiter, resource, batch]
      exporters: [prometheus, logging]

    # Logs pipeline
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, batch]
      exporters: [logging]

  telemetry:
    logs:
      level: info
    metrics:
      address: 0.0.0.0:8888
